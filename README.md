# Researcher: Agentic Writing Assistant

Researcher is an autonomous agent powered by Mistral LLMs that helps you iteratively write and improve scientific manuscripts. It uses a set of integrated tools (retrieval, critique, file I/O, thinking) and an interactive loop to generate, revise, and manage your manuscript based on your data.

## Key Features

- ðŸ¤– Autonomous Agentic Workflow: The agent generates content, solicits self-critique, and applies feedback.
- ðŸ§  Mistral LLM Integration: Chat and embedding models for content generation and retrieval.
- ðŸ“š Retrieval Augmented Generation: Contextual vector search over your document corpus.
- ðŸ”§ Tool-System: `list_files`, `retrieve_relevant_documents`, `critique_content`, `think`, `read_from_file`, `write_to_file`.
- ðŸ’¾ Persistent State with Weave: Save and resume sessions, maintain conversation history, and manage manuscript file.
- ðŸ“„ Manuscript Management: Automatic handling of workdir/manuscript.txt, backups, and versioning.
- ðŸš€ Document Preprocessing: Chunk PDF documents into JSONL for indexing via `researcher_prepare`.
- ðŸ”„ Interactive REPL: Command-line interface to interact with the agent, provide initial prompts, and exit gracefully.

## Installation

```bash
git clone https://github.com/tcapelle/phd_researcher.git
cd phd_researcher
pip install -e .
```

Make sure to set your Mistral API key:

```bash
export MISTRAL_API_KEY=your_api_key_here
```

## Usage

### Preprocess Documents

Process PDF files into a JSONL corpus:

```bash
researcher_prepare --data_dir path/to/your_pdfs --output_file path/to/processed_documents.jsonl --chunk_size 512
```

### Build and Run the Agent

Ensure your vector database exists (created automatically from preprocessed docs). Then start the agent:

```bash
researcher --data_path path/to/ --database path/to/contextual_vector_db.pkl --model_name mistral-medium-latest --max_tokens 1000
```

- On first run, if no database is found, run `researcher_prepare` to generate preprocessed documents.

- The agent will prompt you for an initial manuscript prompt or resume an existing one. Use commands `exit` or `quit` to end the session.

### Command-line Options

```
researcher [initial prompt]           # Start a new session with an initial prompt
researcher --state weave_state_ref    # Resume from a saved Weave state
researcher --data_path my_data        # Path to document corpus
researcher --database my_data/contextual_vector_db.pkl  # Path to vector DB
researcher --model_name mistral-medium-latest           # LLM model name
researcher --max_tokens 1000          # Max tokens for context in retrieval and critiquing
```

## Project Structure

```
.
â”œâ”€â”€ dev/                       # Workshop materials and notebooks
â”œâ”€â”€ my_data/                   # Example data directory
â”œâ”€â”€ researcher/                # Core agent implementation
â”‚   â”œâ”€â”€ agent.py               # Agent loop and logic
â”‚   â”œâ”€â”€ console.py             # CLI interface
â”‚   â”œâ”€â”€ config.py              # Default settings and tool definitions
â”‚   â”œâ”€â”€ tools.py               # Tools available to the agent
â”‚   â”œâ”€â”€ rag.py                 # Contextual vector DB implementation
â”‚   â”œâ”€â”€ preprocess.py          # Document preprocessing utilities
â”‚   â”œâ”€â”€ tool_calling.py        # Weave tool integration
â”‚   â”œâ”€â”€ mistral_helper.py      # Helper functions for Mistral API
â”‚   â””â”€â”€ prompts/               # System and personality prompt templates
â”œâ”€â”€ call_openai.py             # Legacy script, may be deprecated
â”œâ”€â”€ bug.py                     # Debug utilities
â”œâ”€â”€ pyproject.toml             # Project metadata and dependencies
â””â”€â”€ README.md                  # This file
```

## Contributing

Contributions are welcome! Please open issues or submit pull requests.

## License

MIT 